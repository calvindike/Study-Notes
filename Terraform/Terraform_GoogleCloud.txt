Getting started with Terraform for Google Cloud - Google Cloud

##### Introduction to Terraform for Google Cloud #####
Infrastructure as Code (IaC)
This is a way of deploying infrastructure as code instead of manually doing this.
Benefits of IaC
- Declarative: specify desired state of infrastructure, not updates.
- Code management: managed just like a source code (commit, version, trace, and collaborate)
- Auditable: compare infrastructure between desired and current state
- Portable: build reusable modules across an org for scaling.

Provisioning vs Configuration
These are different as tools Iac is used for provisioning but tools like ansible, salt.. are used for configuration management

IaC
- Used for provisioning and managing cloud resources eg. creating and provisioning a VM instance (launching a GKE cluster)
- Referring to frameworks that manipulate Google Cloud APIs to deploy the infrastructure.

Configuration Management
- Used for virtual machine OS-level configuration eg. configuring internals of VMs (deploy containers into the GKE cluster)
- Referring to package configurations nd software maintenance

declarative = I should have 5 servers (what to create)
imperative = Give me 5 servers (how to create)

This declarative will only make sure desired state is matched but imperative will keep provisioning more servers the more it runs.

Terraform is an IaC tool created by Hashicorp that lets us provision Google Cloud resources with declarative configuration files
The language used here is Hashicorp Configuration Language (HCL)

Features
- Multi-cloud and Multi-API
- Enterprise support
- Large community (including a registry)
- Infrastructure provisioning

- We can provision resources
- Create resource dependencies
- Standardize configurations
- Validate inputs to resource arguments

Standard IaC Configuration Workflow
1. Scope: Confirm the resources required for a project
2. Author: Author/write the configuration files based on the scope
3. Initialize: Download the provider plugins and initialize directory
4. Plan: View execution plan for resources created, modified, or destroyed.
5. Apply: Create actual infrastructure resources


Terraform use cases
- Manage infrastructure: Terraform takes an immutable approach to building and managing infrastructure.
- Track changes: Terraform enables us to review the changes before they are applied to the configuration setup (this is done by checking with the state files)
- Automate changes: Terraform defines the end state of the infrastructure instead of a series of steps to achieve it
- Standardize the configuration: Terraform uses modules to implement best practices and improve efficiency

Using Terraform
- Terraform recognizes config files written in .tf file
- Terraform generates an execution plan (terraform plan -out <file>)
- Terraform uses this plan to create infrastructure (terraform apply <file>)
- Terraform determines the changes and creates incremental execution plans

3 Terraform tiers
- Community Edition
- Terraform Cloud
- Terraform Enterprise

##### Terms and Concepts ######
- Terraform uses configuration files to declare an infratructure element.
- The configuration is written in terraform language with a .tf extension
- A configuration consists:
	- A root module/root configuration: this is the working directory where the terraform commands are run -- has the main.tf file.
	- Zero or more child modules ( a directory inside the root module that could contain main.tf, providers.tf, variables.tf, outputs.tf, terraform.tfvars )
		Note: variables.tf, outputs.tf, and terraform.tfvars are optional but recommended.

Terraform will look for any .tf files in the root module/working directory and use them to create a plan and infrastructure elements

HCL - Hashicorp Configuration Language
- Used to create and manage API-based resources predominantly in the cloud. 
Terraform uses HCL to define resources in our cloud environment, create dependencies with the resources, and define the datato be fetched. 
*Resources are infrastructure objects such as VM's, Storage buckets, Containers, Networks
- HCL is a configuration language, not a programming language
- It includes limited set of primitives such as variables, resources, outputs and modules
- It does NOT include traditional statements or control loops.

HCL Syntax
<BLOCK_TYPE> "<BLOCK_LABEL" "<BLOCK_LABEL>" {
  # Block body
  <IDENTIFIER> = <EXPRESSION> #Argument
}

Blocks
Arguments
Identifiers
Expressions
Comments

Blocks: lines of code that belong to a certain type eg: resources, variables, outputs. A block can be simple or nested to include another block type.
Arguments: part of a block and used to allocate a value to a name. Some blocks have mandatory arguments while others are optional.
Identifiers: names of an argument, block type, and any Terraform-specific constructs. Identifiers can include letters, underscores, hyphens, and digits (they cannot start with a digit)
Expressions: can be used to assign a value to an identifier within a code block. These can be simple or complex.
Comments: starts with a hash (#) for single-line comment.

*Note that the order of the blocks or files does NOT matter since HCL is a declarative language

				######### Resources #########
Resources are code blocks that define infrastructure components. A resource is identified by the keyword, resource, followed by the resource type, and resource name

resource "google_storage_bucket" "example_bucket" {
  name	= "<unique_bucket_name>" //Required
  location = "US"
}

resource "google_compute_instance" "my-instance" {
  name = "test"
  machine_type = "e2-medium"
  zone = "us-central1-a"
  boot_disk {
      initialize_params {
        image - "debian-cloud/debian-9"
       }
  }
  network_interface {
    network = "default"
    }
  }
}
In this case, we have 2 resource blocks - the first resource type is google_storage_bucket and resource name is example_bucket while the second resource type is google_compute_instance and resource name is my_instance.
Terraform uses the resource type and name together as an identifier for the resource.
For the first resource, we must specify the name and location arguments to sucessfully create resource
For the second resource, we must specify the name, machine_type, and network_interface arguments to create an instance. Zone and tags in this case, are optional. 
We can use separate files, for example: files for instances, storage buckets, and datasets if we haev lengthy resource configurations.

				######### Providers #########
Providers implement every resource type. Without providers, terraform cannot manage any type of infrastructure. In the providers.tf block, we secify the providers block that we will use.
Terraform downloads the provider plugin in the root configuration when the provider is declared.
Providers expose specific APIs as terraform resources, and manage their interactions.

terraform {
  required_providers {
    google = {
      source = "hashicorp/google"
      version = "4.23.0"
    }
  }
}

provider "google" {
  # Configuration options
  project = <project_id>
  region = "us-central1"

Arguments such as project and region in the provider block are specific to this google provider. When a provider block is not included within a Terraform configuration, Terraform assumes an empty default configuration.
An optional argument that is recommended is the version argument which constrain the provider to a specific version, to prevent downloading a new version that could contain breaking changes. When a version is not specified, the most recent provider version will be downloaded during initialization.

				########### Variables ############
Variables are used to parameterize our configuration. We parameterize arguments to eliminate hard coding values eg: Region, project ID, zone ...
We can define a resource attribute at run time or centrally in a file with a .tfvars extension.
Input Variables: serve as parameters for terraform allowing easy customization and sharing without having to alter source code
Eg:
- In main.tf (Declare storage bucket)
location
storage_class
- In variables.tf (Parameterize resource attribute)
variable location {
 ..
}
- In terraform.tfvars (Define values at run time or in a file)
location = "US"
storage_class = "STANDARD"

				########### Outputs ###########
Output values are stored in outputs.tf file. The output values expose values of resource attributes. The output of the resource values which can be used elsewehere in our configuration are gotten via the output.tf file. Some of the attributes are gotten after terraform creates the resource. The label after the output keyword is the name which must be a valid identifier. In a root module, the name is displayed to the viewer, but in a child module it can be used to access the value. The value argument states an expression that returns the value argument to the user.

output "bucket_URL" {
  value = google_storage_bucket.mybucket.URL
}

Output after terraform apply
Outputs:
bucket_URL = "https://storage.googleapis.com/my-gallery/..

				##### State #####
Terraform saves the state of resources it manages in a state file. By default the state is stored locally, but it can also be stored remotely in a shared location, which is the preferred method.
Do NOT modify the state file.
				######## Module #########
A terraform module is a set of terraform configuration files in a single directory. 
This is the primary method for code reuse in Terraform.
There are 2 kinds of sources:
 - Local: source within your directory
 - Remote: source outside your directory

We can use an upstream module from the terraform module registry or create our own.

Terraform Commands
- terraform init: initialize the provider with plugin. The provider block will have a source attribute that specifies where the plugins will be downloaded from.
After this command it ran, a .terraform directory will be created where the installed binaries will be.

- terraform plan: preview of resources that will be created after terraform apply. when this is ran, terraform reads the current state of existing remote objects to ensure that terraform state is up to date, compares current configuration to prior state to note any differences, then builds an execution plan that only modifies what is necessary to reach desired state. This provides us the opportunity to preview changes that will be made when we run our state.

- terraform apply: executes plan and creates real infrastructure resources as well as establishes the dependencies.
Symbols that show wheen this is ran:
+ = create resource
- = destroy resource
-/+ = replace (destroy and then create, or vice-versa if create-before-destroy is used)
~ = update resource in-place
<= = read

To skip typing in yes, add -auto-approve to your command

- terraform destroy: destroy infrastructure resources. We can also destroy specific resources by specifying a target in the command

- terraform fmt: auto format configuration files to match canonical conventions

- terraform validate: testing syntax


Terraform validator: this is different from the 'terraform validate' command. It runs pre-deployment checks against organizations policies to detect policy violations. Useful in CI/CD pipelines. 
Example use case
- Platform teams can add guardrails to infrastructure CI/CD pipelines to ensure all changes are validated.
- Application teams and developers can validate Terraform configuration with organization's central policy library.
- Security teams can create a centralized policy library to identify and prevent policy violations.

Writing Infrastructure Code for Google Cloud
Introduction to Resources
Resources are infrastructure elements you can configure using Terrafirm eg: Compute Engine instance, VPC, Cloud Storage bucket, Firewall rules
There are multiple resources and resource types in the real world.
Terraform uses the underlying APIs of each Google Cloud service to deploy your resources.
Resources are defined within a .tf file. The resource block represents a single infrastructure object.
The resource type identifies the type of resource being created, and this resource type depends on the provider being declared within a terraform module. Generally, a provider is a cloud infra platform.
Attributes can be used to define any advanced features associated with a resource. Not all arguments must be defined.
We can include multiple resource blocks within same configuration file and these resources can even span against multiple providers.

resource "resource_type" "resource_name" {
  #Resource arguments
}

resource "google_compute_network" "vpc_network" {
  name = "vpc-network" #Required argument
  project = "<Project_ID>"
  auto_create_subnetworks = false
  mtu = 1460
}

To refer to a resource attribute:
<resource_type>.<resource_name>.<attribute>
google_compute_network.vpc_network.name = "vpc-network"

Considerations for definint a resource block:
- The resource name of a given resource must be unique within the module.
- The resource type is not user-defined and is based on the provider (must match the term mentioned in Terraform registry)
- All configuration arguments must be enclosed within the resource block i.e within the curly brackets.
- All required resource arguments must be defined else, there will be an error of missing argument.

Meta-arguments for resources
These can be used with any resource tyoe to change the behavior of the resources.
- count: create multiple instances according to the value assigned to the count
- for_each: create multiple resources according to a map or a set of strings
- depends_on: specify explicit dependencies
- lifecycle: define life cycle of a resource. With this, we can prevent the deletion of a resource for compliance purposes. This is used for high availability
- provider: select a non-default provider configuration.

count:
Instead of having multiple resource blocks (redundant code) to create different instances, we can have all those in one block using the count meta-argument

resource "google_compute_instance" "dev_VM1" {
  name = "Dev_VM1"
}
resource "google_compute_instance" "dev_VM2" {
  name = "Dev_VM2"
}

turns to:

resource "google_compute_instance" "dev_VM" {
  count = 2
  name = "Dev_VM${count.index + 1}"
  #Other required arguments
}

for_each:
Count is used when our instances are almost identical. If some of the arguments cannot be derived from an integer, it is better to use for_each.
for_each argument can be assigned to a string of values or a map. Terraform will create one instance for each member of the string.
An example is when we need 3 similar instances but created in 3 different zones, and we want the names to have the zones as prefixes for identification.

resource "google_compute_resource" "dev_VM" {
  for_each = toser( ["us-central1-a", "asia-east1-b", "europe-west4-a"] )
  name = "dev-${each.value}"

  zone = each.value
  #Other required arguments
}

This will create 3 instances with the names: dev-us-central1-a, dev-asia-east1-b, dev-europe-west4-a.

Resource Dependencies
While building infrastructure, we could want a visual representation of how our infrastructure is connected. A dependency graph helps us understand our infrastructure before deployment. Terraform builds the dependecy graph for our configurations to generate plans and refresh states. 
Terraform creates a dependency graph to determine the correct order of operations and will perform operations in parallel when it is safe to do so.

2 types of dependencies terraform can handle
- Implicit dependency: dependencies known to Terraform are detected automatically
An example of implicit dependency which is handled automatically by Terraform is the fact we cannot create a compute instance until the network is created, or that we cannot assign a static IP to a compute instance until a static IP is reserverd.
- Explicit(unknown) dependency: dependencies unknown to Terraform must be configured explicitly.
We can use depends_on to declare an explicit dependency to Terraform. Example is when we want to create a client VM only after the Server VM has been created. 
In the code below, we're telling Terraform to create the client compute instance only after the server compute instance has been created.

resource "google_compute_instance" "client" {
  ...
  depends_on = [google_compute_instance.server]
}

When we run 'terraform apply' we can see the order in which things are created.

Variables
Variables parameterize our configuration without altering the source code. Without variables, resource arguments are hardcoded within the configuration which is NOT the best practice.
Variables allow us to assign a value to the resource attribute at run time.
After a variable is defined, there are different ways to set it's value at run time, including environmental variables, CLI options, and key-value files i.e Variables separate source code from value assignments.
Variables must be declared in the variables block and it is recommended to save all variables in variables.tf or vars.tf

Syntax:
variable "variable_name" {
  type = <variable_type>
  description = "<variable_description>"
  default  "<default value of variable>"
  sensitive = true # left as true because if it is not sensitive, you can ommit the sensitive argument
}

variable "bucket_region" {
  type = string
  description = "Region for bucket"
  default = "US"
  sensitive = true
}

2 rules for naming variables
- name of the variable must be unique within a module
- variable names cannot be keywords

types: bool, number, string
When no value is set for a variable. the value specified in the default argument is used.
The name of the variable in the variable block has to match the reference made within the resource block. The default value can be changed by assigning a value as an environmental variable or if the .tfvars file which is pointed to by using -var

- tf apply -var-file my-vars.tfvars (recommended method - useful for quickly switching between sets of variables and versioning them)
- terraform apply -var project_id="my-project" (CLI options - useful when running quick examples on simple files)
- TF_VAR_project_id="my-project" \ (environmental variables - useful in scripts and pipelines)
tf apply
- tf apply (using terraform.tfvars)

Remember there is an order of operation on which method is used above the other.
The description documents the purpose of the variable
sensitive is a way of preventing sensitive information from being displayed in the cmd output or log files. eg. API tokens or DB creds

Use variables only when necessary
- Only parameterize values that must vary for each instance or environment
- Changing a variable with a default value is backward-compatible
- Removing a variable is not backward-compatible
- For root modules, provide values to variables using .tfvars file
- Give variables descriptive names
- Provide meaningful descriptions

Output 
Output values are similar to return values in regular programming languages
They expose information about the resource to the user of the Terraform configuraton. We can view information about the resources we created on the cmdline
We can extract say an IP address and input it to another resource that needs it.
Arguments in an output block
- value: returns a value
- description: optional argument that provides an explanation of the purpose of the output and expected value.
- sensitive: mask values to a resource attribute

It is recommended to use output values, instead of user-supplied inputs for computed attributes of a resource.
To query all output values run:
$ terraform output
Make sure outputs are declare in outputs.tf file

Terraform Registry: Intereactive resource for discovering providers and modules. Solutions developed by Hashicorp, third party vendors, and the Terraform community.
It provides plugins

Cloud Foundation Toolkit(CFT): Provides a series of reference modules for Terraform that reflect Google Cloud best practices.
CFT modules can be used without modification to quickly build a repeatable enterprise-ready foundation in Google Cloud.
CFT modules are also referred to as Terraform blueprints.

- You can also use Cloud Foundation Fabric (CFF), a collection of modules and examples for fast prototyping or to be modified and used in organizations.

Organizing and Reusing Configuration with Terraform Modules
Dont Repeat Yourself Principle - DRY 
This is a method used in order to not repeat the same set of code multiple times. Terraform uses modules to achieve this.
We can group sets of resources together so we can reuse them later. When we need to edit this code, we only do it in one place.
Instead of repeating same code, we use abstraction to avoid redundancy - This practice encourages building efficient code that is readable and reusable.
In general putrpose programming languages, functions are used to implement the DRY principle. In terraform, we can use modules to achieve this and this module can be reused in multiple places. 
Module: a group of one or more cnfiguration files (.tf) in a directory.
- allows us to group a set of resources together and reuse them later.
- modules can be reference in other modules

To create modules, we'll need to create separate directories, enter the cide in network
$ mkdir network && cd network
$ touch main.tf outputs.tf variables.tf
$ vi main.tf
resource "google_compute_network" "mynetwork" {
  name = "mynetwork"
  auto_create_subnetworks = true
  routing_mode = global
  mtu = 1460
}

resource "google_compute_firewall" "default" {
  #All necessary parameters
}

-----> In the example above, notice we have multiple resources grouped in the network module, and in the one below, we have a server module.

$ mkdir server
$ touch main.tf outputs.tf variables.tf
$ vi main.tf
resource "google_compute_instance" "server_VM" {
  #All necessary parameters defined
}

When a module is called, the same resources will be used.
Benefit of Modules
- redability: eliminates multiple lines of code
= reusability: code can be reused multiple times easily
- abstract: separate configs into logical units which reduces theit dependency as well as making it easier to debug.
- cosistent: helps us package the configuration of a set of resources.

After modules are created, we can call them in our Root main.tf file(note that the main.tf files for network and server are not in our root directory as we created new directories for those).
example Root main.tf
provider "google" {
region = us-central-1 
}

module "web_server" {
source = "./server"
}

module "server_network" {
source = "./network"
}

We run the 'terraform init' command to download any modules referenced in our configuration.
The source meta argument is used to point to the location of the module source code.
Every module called within terraform requires a source meta argument that points to a location which can be a local or remote path.
Several remote source types: Terraform Registry, GitHub, Btbucket, HTTP URLs and Cloud storage buckets.
- Local paths are stored within a directory in the root module path. Local paths do NOT require any installation. 
- For Terraform Registry, the source address has t be in the format namespace/name/provider
eg. Terraform Registry 
module "web_server" {
  source = "terraform-google-modules/vm/google//modules/compute_instance"
  version = "0.1.4"
}

To use this module, we can use
terraform-google-modules/gcloud/google
Namespace--------------/Name--/Provider

You are recommended to use version to avoid any unwanted behavior.

Hard coding modules are not the best as we risk running into an Error regarding the resource already existing.
Error 409: The resource "<resource>" already exists

To parameterize our network module for instance, we replace the hard coded arguments with a variable in the main.tf file, declare the variables in the variables.tf file, then pass the value of the input variable when you call the module:
$ vi network/main.tf
resource "google_compute_network" "vpc_network" {
  name = var.network_name
}

$ vi network/variables.tf
variable "network_name" {
  type = string
  description = "name of the network"
}

$ vi main.tf (Root main.tf)
...
module "dev_network" {
  source = "./network"
  network_name = "my-network1"
}

module "prod_network" {
  source = "./network"
  network_name = "my-network2"
}

NOTE: You cannot pass values to variables for modules ar run time.

To pass resource arguments from one module to another, the argument must be configured as an output value in terraform.
For example, if we want to pass the network name to the server module, we declare the output value in the network directory outputs.tf file, declare the argument as a variable in the server module, then refer the output value when calling the server module :
$ vi network/output.tf
output "network_name" {
  value = google_compute_network.my_network.name
}

$ vi server/main.tf
resource "google_compute_instance" "server_VM" {
..
  network = var.network_name
}

$ vi server/variables.tf
variable "network_name" {
}

$ vi main.tf (Root main.tf)
module "server_VM1" {
  source = "./server"
  network_name = module.my_network_1.network_name
}
module "my_network_1" {
  source = "./network"
}
$ terraform init

Best practices for using modules
- Don't overuse them
- To loop over values, use terraform for_each or count instead of writing you own code
- Use local modules to organize and encapsulate your code
- Use the public terrafor registry to find modules
- publish or share your modules with your team


Terraform States
Infrastructure changes are tracked using the terraform state. This pretty much describes the state of our infrastructure.
State files can be stored in remote locations. 
Terraform state is a metadata repository of our infrastructure configuration. (terraform.tfstate) Terraform state stores the bindings between objects in a remote system and resource instances.
When terraform creates a remote object from our terraform configuration, it will record the identity of the object or instance, and updates or deletes it in response to our configuration changes.
When 'terraofrm apply' is ran for the first time, objects are created as well as the state file being automatically created to have a record of all those changes. When we run apply again, it will check the state file to compare that with what we have in our configuraiton.
By default, terraform svaes the state file locally in the current working directory.
When working in a team where multoiple developers are working, this should be a remote state file.

Issues with storing Terraform state locally
- No shared access
- No locking: if 2 people run changes simultaneously, it could corrupt the state
- No confidentiality: state file exposes all sensitive data such as username and password of database which could be in plain text.
Benefits of storing remotely
- Automatic updates: remote state supports automatic updates to the state file
- Locking: cloud storage buckets natively support state locking
- Decure access: Google Cloud Storage buckets support encryption and IAM policies.

To remotely store terraform state in a CLoud storage bucket:
$ vi main.tf
resource "google_storage_bucket" "default" {
  name = "<my_bucket_name>"
  force_destroy = false
  location = "US"
  storage_class = "STANDARD"
  versioning {
    enabled = true
  }
}
$ vi backend.tf
terraform {
  backend "gcs" {
    bucket = "<my_bucket_name>"
    prefix = "terraform/state"
  }
}
}

$ terraform init - copies local state to the remote state and uses remote state going forward.

- Use remote states when working in teams: supports locking and versioning
- Use gitignore for terraform state files
- Avoid storing secrets in state because terraform stores secret values in plain text.
- Encrypt state file: use customer-supplied encryption keys to add a layer of protection
- Do NOT modify terraform state manually instead, use the 'terraform state' command when you need to modify a state.

